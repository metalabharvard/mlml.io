---
title: Where will your values take AI? Co-designing a Moral Labyrinth
intro: ""
start: "2019-06-14"
end: "2019-01-01"
location: Tunis, Tunisia
host: harvard
mediation: mixed_media
category: ""
isFeatured: false
externalLink: ""
lastmod: "2021-09-15T15:46:22.872Z"
date: "2019-06-14"
slug: where-will-your-values-take-ai-co-designing-a-moral-labyrinth

---
**[Tunis 2019 metaLAB Workshop](https://rightscon2019.sched.com/event/Pvfz/where-will-your-values-take-ai-co-designing-a-moral-labyrinth-and-taking-one-home)<br />
Where will your values take AI? Co-designing a Moral Labyrinth (and taking one home!)<br />
Sarah Newman, Jie Qi, Mindy Seu**

**Friday June 14, 2019<br />
9-10:15 am<br />
Rightscon Tunis, Tunisia**

This workshop, led by artists and designers from Harvard University and the University of Tokyo, will bring together participants to think through difficult questions questions about human relationships to technology, and create a visual work that each participant will get to take home. The session is inspired by the Value Alignment Problem: the challenge of assuring that the goals embedded in intelligent systems (or the secondary goals they subsequently form) are aligned with the values of the society they serve. The session will include: discussion morality across cultures, creative exercises geared toward generating diverse questions, and compiling the participant-generated questions into "moral labyrinth." 

The labyrinth will include as many voices as there are workshop participants, in as many languages as possible. The session will conclude with participant-generated labyrinths, and each participant will get to take one home. After RightsCon, the collective Moral Labyrinth will be posted online to share with others, and visitors to the site will also be able to submit their own moral questions for reflection. The workshop encourages collaborative reflection on value alignment in the 21st century -- emphasizing the necessity of asking questions as we co-create and steer toward our shared technological future.